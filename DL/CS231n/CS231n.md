# Introduction
***
# Image Classification pipeline
## challenges 
* 图片是由无数数字块组成的
* 视角的转变，亮度的变化，变形都会产生非常大的变化
	* viewpoint
	* illumination
	* deformation
	* occlusion
	* background clutter
	* intraclass variation

## image classifer
* input:image
* output: class_label

## data-driven approach
* 其他方法不行
	* attempts: 边缘检测，纹理等等（但是太过具体）
* 以数据为导向的方法
	* def train(image, label)
	* def predict(model, test_image)

## KNN
### NN
* 对于每一个测试的data，在数据库里面找到离他最近的图片（选择一共找多少张，这么多张里面投票）
* 定义距离（hyperparameter）
	* 曼哈顿距离 L1: 两张图相减求绝对值，然后把整张照片求和
	* 欧几里得距离 L2: 距离的平方和开方
* 实现
	* training：记住每个图片的内容和label
		* image：N✖D，每行是一张图片（拉成一行），一共N张
		* label：1-d数组，sizeN
	* predict：计算距离找到最小的角标（np.argmin)
* 速度：linearly to size of dataset
* 缺点：
	* 预测的时间太长了（expensive）
	* 但是我们希望训练的时间长但是测试的时间短（CNN）

### KNN
* 找到最近的K个，投票
	* 当K增加的时候，整个图片的边缘变得平滑了
	* K的数量也是一个hyperparameter
* 需要选择的hyper（并不能很好的找到最优解）
	* K
	* 用什么distance
	* 如何选择最好的参数
		* 总不能尝试所有的参数吧2333
		* 不能使用test data，请在训练的时候忘记自己拥有它
		* 把train data fold成不同的部分，把其中的一部分当成测试数据（validation data），然后测试训练的结果寻找hyper
		* 交叉验证（cross-validation），循环当validation fold然后average result

### 但是根本不用呢
* 在test time的performance太差了
* 两个图片之间的距离太不直观了，你根本不知道图片间的距离会怎么变

## linear classification
### parametric approach
* 输入：32x32x3的图片，array of numbers 0,1,...3072
* f(x,W) = Wx + b （**在线性分类的情况下**） （10x1）
	* x: image （3072x1 -> 拉直了）
	* W: parameters，weights （10x3027）
	* b： bias （10x1），不是这个函数的参数，只是用来决定比如猫的数量特别多，偏向猫的bias可能就比较大
* 输出：10个数字，表示每个class的scores

### 注意
* W是把不同分类的classifer拼在了一起（乐高一样），每一行都是一个不同的class的分类器，点乘这个图片上面的像素，加上bias就是这个图片最终的得分
* resize所有的图片到一个大小（目前）
* 实际上每个class的score就是图片里面每个点的加权求和，可以想象成在数每个不同地方的点的颜色。如果把W矩阵还原，还原出来的就是这个class的感觉上的颜色
* 可以想象在一个巨高d的space里面，用线性分类

### hard part
* 都用灰度图会有问题
* 相似的texture（？

***
# loss function optimization
todo：
* 定义一个loss function来定义这个score的好坏
* 找到一个efficiently way去找到minimize 这个loss

## SVM loss
### 定义
* 假设如果只有三个种类，一张图片对三个class分别会有不同的score。每张图片都可以计算出一个对应的loss
* SVM loss Li = sum max（0，sj - si + 1）
	* si: 想要计算这个的loss function 的class的评分（也就是label标注的class的评分）
	* sj: 这张图对于所有其他种类（除了i）的评分
	* Li: 最终这张图片的loss
	* 1: 是一个safety margin（也是一个hyper parameter）。可以选择其他正数，但是选0会出问题
	* Li的每一项都在0和差值之间找最大值，然后把每一项的加起来求和
* 如何理解这个式子：既然对于不同class的评分越高就是越可能，那么评分是负数的话就说明不可能，这样就直接用0把这种可能性抹去了。如果其他种类在正的方面评分越高，说明这个种类跑偏了，loss越大

![SVM](images/L3_1.jpg)

###注意点
* 在上面这张图里，因为车的评分已经是最高了，计算出来的loss就是0
* 最后再把所有类型的loss求和，除以种类得到最终的loss
* 用的是求和而不是mean也是取决于自己的决定
* 也有的SVM里面用的是max之后平方，但是不平方的用的更多一点，也是一个hyper parameter
* scale
	* 最小：0
	* 最大：infinite 
![python code](images/L3_2.jpg)

### bug
* 在实际应用里面没有那么好的效果
* W不是唯一的，比如把这个W加倍，如果loss是0的时候是一样的 -> 需要得到唯一的W

### weight regularization（解决上面这个问题）
* 在之前的loss的基础上加上了 \lambda R(W)
	* \lambda是一个hyper parameter，是取决于自己的选择的
	* R是一个regularization函数，这个函数的作用是抵抗之前的loss。因为之前的loss是从训练集上得到的，比较吻合训练集，所以需要一个比较特别的W来和之前的fight，这样的话结果可能会在实际使用的时候更好一些
* 主要分类
	* L2 regularization：W里面的所有项平方然后求和（最常见）
	* L1 regularization：W里面所有项绝对值然后求和 -> 在一些其他地方使用
	* elastic net（L1+L2）：所有项平方乘参数加绝对值求和
	* max norm regularization -> 后面讲
	* dropout
* 理解L2
	* 比如X是[1,1,1,1],两个W分别是[1,0,0,0]和[0.25,0.25,0.25,0.25]
	* 这样乘出来的最终结果都是一样的，都是1。
	* 但是如果加上了L2的regularization之后就发现第二种方法的loss更少一点。因为他用到了更多的维数，在实际应用之中效果更好。

## softmax（用起来更好）（multinomial logistic regression）
### 定义
* scores：unnormalized log probabilities of the class 
	* 需要把score先exp回来(这样所有的数都变成正数了)
	* 再normalize（除以所有exp之后的的和）
	* 最终，对于正确class的最终处理完的score来说，max这个log或者min（loss function）- log会得到最终最好的结果
* 最终处理完的score就是每个类型推测出来的占比可能性（和为1）
* 这里求完-log（p）其实就是信息熵，代表对不确定度的度量
	* 直接比较可能性和log之后比较可能性在本质上是没有区别的
	* 但是数学上一般log之后的数据会看起来好一些
![softmax function](images/L3_3.jpg)
实际操作如下
![softmax result](images/L3_4.jpg)

### 一些问题
* 极值
	* Li最小值：0 -> 如果正确类型的可能性是1，求出来的最终值就是0
	* Li最大值：infinite，可能性非常低非常接近于0
* 当W的初始化很小，所有score都接近于0：
	* score求exp之后都是1，normalize之后是1/num（class），最后再求log
	* 可以用于开头的检验
* SVM和softmax
	* 如果输入是[10,-100,-100]，在这个范围里微小变化，第一个是正确的class
	* 对于SVM来说，后面两个负值都非常小了，根本不会去管后面的两个东西，-100和-200没啥区别
	* 对于softmax来说，后面的-100还是-200还是会对loss最终的值产生影响，softmax希望所有的值都在正确的class上面，后面啥都没有。所以更具有robustness。
* SVM会有一个你需要的区域，剩下的根本不考虑；而softmax会考虑所有的区域

## 上方区域总结
![总结](images/L3_5.jpg)
* x：训练集里面的数据，放在图片里就是把一个图片拉成一个1xN的向量
* y：训练集的标签，用来和最终的结果比对
* W: weights，需要优化的部分
* L：loss，用来权衡W优化结果的好坏
* 基本过程
	* Wx+b得到目前的分类器的score（score function）
	* y是目前分类应该有的结果（label）
	* R（W）得到regularzation的值
	* 分类器得到score，y知道正确的分类，通过softmax或者SVM得到这个分类器目前的loss，再加上R（W）的部分增加robustness最终得到整个分类器的loss

## optimization loss
### follow the slope
* 通过计算gradient来找到最低点
* 最基础的想法：（从数学上入手）
	* 因为梯度是lim f(x+,h)-f(x)/h
	* 把W上面的每一个点都加上一个0.00001（接近于0）然后再求上面的式子，就能得到第一次操作的梯度
	* silly
		* 每一步都需要每一个维度都算一下，在CNN里面参数高达百万个，计算太慢了
		* 因为用的0.00001，其实并不准确
* 感谢牛顿莱布尼兹发明了微积分 -> 如何具体计算在下一节课
	* 把loss的gradient改成了一个式子
	* 快速，准确，然是容易发生bug（error-prone）
* **practice**需要进行gradient check
	* 在写代码的时候用的肯定都是analytic gradient
	* 但是需要在应用之前用numerical gradient检查一下，确保两者的结果是一样的，为了保证代码里面写的积分是正确的

### gradient descent
![gradient descent](images/L3_6.jpg)
* mini-batch
	* 在实际应用的时候，不会把整个的训练集都拿来优化W，而是会把一部分拿出来（sample examples）
	* 一小点一小点的拿结果不会非常准确，但是可以step很多次，在实际应用里面一般都不会用整个training set，不是很现实而且效果不是很好。
	* 选择的数量上 32/64/256，这个不是一个很重要的hyperparameter，主要是根据GPU的性能来决定的
	* 最终结果的loss是会下降的，虽然noise很多但是最终会go dowm
* learning rate
![learning rate](images/L3_7.jpg)

## 图片中使用linear classifier
因为图片像素太多了，不可能对每个像素都用线性分类，所以一般会先提取一些特征然后得到最终的分类结果
### color histogram
* 先得到一张图片的颜色特征分布
* 然后把整个特征分布拽成一个长的vector进行分类

### HOG/SIFT
* 找到边缘特征，在图片的哪个部分有那种样子的edge

### bag of words
* 先把图片里面的一些特征当作一个vocabulary，然后放进一个词典里面
* 找到词典里每个词出现的频率然后拽成vector
* 线性分类

### 总结
一般都是先进行特征提取然后再进行线性分类 <-> 深度学习特征都是自己提取
***
# Backpropagation & neural network
目的：求出来loss function的gradient
## backpropagation
![example](images/L4_1.jpg)
最右边的点因为是df/df所以结果就是1

* forward pass：知道开始然后一直顺到结束
	* 在一个node上面，收到了x和y的input，对他们进行f操作，得到最终的结果z
	* z再往后操作得到最后的loss（不知道什么操作）
* backward pass：从后到前，通过链式法则倒回来
	* 虽然不知道loss对x或者y的gradient，但是可以求出来dz/dx和dz/dy（只和这个点有关）
	* 可以得到dL/dz，然后乘以local gradient
![local gradient](images/L4_2.jpg)
* local gradient
	* 每一个node上面的gradient往前推的时候，都可以通过链式法则（chain rule）变成这个点输入的gradient和这个点到上一个点的gradient的乘积。
	* 算local的时候，乘的参数是输入进去的参数啊。比如dL/dx = dL/dz（这个带这个点back回来的数字） * dz/dx （这个里面的x带这个点输入进来x的值）
	* 想不明白的时候把不同的点假设成不同名字然后求导！
	* 在这个网络里面，如果gate是加法（x + y）的话不是求偏导，如果求x的导数的话y并不是参数而是常数，所以求出来的结果是1，所以加法的gate就是直接把这个值相等的分开
		* 加gate是一个gradient distributor，当一个gradient进来的时候会被相同的分开成了两份
	* 也可以把一些gate组成一个大的gate，比如sigmoid
* 注意，求出来的gradient如果是正的，说明这个点对最终的**loss**有positive的作用
* patterns
	* add：gradient distributor
	* max：router
		* 假设f是max（x，y）
		* local gradient对最大的那个就是1，对其他的都是0
		* 因为如果没能通过max的gate的话根本对后门的loss没有影响。back的时候走最大的点就可以了，其他的都不用管了
	* multiply：switcher，真，两极反转
* 当往回的时候，两个点指向一个点，gradient需要相加（如下图）
![branch](images/L4_3.jpg)

## Implementation
### psuedocode
* graph or net object
	* forward:
		* 把input pass进这个gate里面（必须在代码里面记住input）
		* 把整个computational的garph往前推动
		* 最后一个gate会return这个网络的loss
	* backward
		* 输入dz，然后乘不同的x和y
* 不同的gate分别是不同的文件（API），每个文件里面包括初始化，forward和backward
* 每次update的时候都需要进行forward和backward，forward得到gradient，backward再回来求最终的loss

### vectorized
* 在实际的计算中x，y，z都是矩阵，dz/dx是jacobian矩阵（全部都由偏导组成的矩阵）
* 比如一个max的门，如果输入是1x4096，输出也是1x4096，但是求偏导出来的矩阵是4096x4096（太大了），矩阵中间只有对角线部分的是需要考虑的（还会有很多0）
	* 然后如果用了minibatch的100，得到的结果就是409600了，更可怕了
	* 所以在每次API的时候，肯定不能写出来所有的链式法则，只用其中的一部分
	* **作业的重点就是如何让这个东西计算出来效率高**

## neural network
### 两层的NN
![branch](images/L4_4.jpg)
* 输入是图片一共的坐标数量
* 先通过第一层（max）得到100的中间层（hidden layer）-> 100是hyperparameter，自己定的，但是越多越好吧
* 然后通过W2得到最终的分类结果（分10类）
* 其实具体里面是什么东西真的是不知道的？
![code](images/L4_5.jpg)

### 神经元
* 每个神经元的输入是Wx+b，然后经过激活函数 输出
* 激活函数 activation function
	* sigmoid
	* tanh
	* ReLU
* 层状 -> 可以更加efficient

# 作业相关内容
## 安装anaconda！！！ conda activate cs231n
## python3 -m IPython notebook 打开！！
## assignment1
### knn
* 两次循环计算距离
	* 不需要一个像素一个像素的计算，用X直接表示i对应的那行的像素值的和，直接做差（每一项之间，平方（每一个，求和（所有项），开方。会快很多！！！！
	```
	#dists是一个500x5000的矩阵（测试数量和训练数量）
	        dists[i,j] = np.sqrt(np.sum(np.square(X[i] - self.X_train[j])))
```
	* 初始化数组的方法是 np.array([[],[]])
	* 如果一个像素一个像素的循环结果简直太可怕了，害怕